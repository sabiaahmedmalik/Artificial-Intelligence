{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41ba4379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate: 76.0 %\n",
      "Average Path Length: 8.263157894736842\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import heapq\n",
    "\n",
    "# Grid size\n",
    "N = 5\n",
    "\n",
    "# Directions: up, down, left, right\n",
    "DIRS = [(0,1), (1,0), (0,-1), (-1,0)]\n",
    "\n",
    "# Manhattan distance\n",
    "def heuristic(a, b):\n",
    "    return abs(a[0] - b[0]) + abs(a[1] - b[1])\n",
    "\n",
    "# Simple A* search\n",
    "def astar(grid, start, goal):\n",
    "    pq = [(0, start)]\n",
    "    parent = {}\n",
    "    cost = {start: 0}\n",
    "\n",
    "    while pq:\n",
    "        _, current = heapq.heappop(pq)\n",
    "\n",
    "        if current == goal:\n",
    "            path = []\n",
    "            while current != start:\n",
    "                path.append(current)\n",
    "                current = parent[current]\n",
    "            return path[::-1]\n",
    "\n",
    "        for d in DIRS:\n",
    "            r = current[0] + d[0]\n",
    "            c = current[1] + d[1]\n",
    "            nxt = (r, c)\n",
    "\n",
    "            if 0 <= r < N and 0 <= c < N and grid[r][c] == 0:\n",
    "                new_cost = cost[current] + 1\n",
    "                if nxt not in cost or new_cost < cost[nxt]:\n",
    "                    cost[nxt] = new_cost\n",
    "                    priority = new_cost + heuristic(nxt, goal)\n",
    "                    heapq.heappush(pq, (priority, nxt))\n",
    "                    parent[nxt] = current\n",
    "    return None\n",
    "\n",
    "# Random wall changes\n",
    "def change_walls(grid):\n",
    "    r, c = random.randint(0, N-1), random.randint(0, N-1)\n",
    "    grid[r][c] = 1 - grid[r][c]\n",
    "\n",
    "# Run one test\n",
    "def run():\n",
    "    grid = [[0]*N for _ in range(N)]\n",
    "    start = (0, 0)\n",
    "    goal = (N-1, N-1)\n",
    "    current = start\n",
    "    steps = 0\n",
    "\n",
    "    while current != goal:\n",
    "        path = astar(grid, current, goal)\n",
    "        if path is None:\n",
    "            return False, steps\n",
    "\n",
    "        current = path[0]\n",
    "        steps += 1\n",
    "        change_walls(grid)\n",
    "\n",
    "    return True, steps\n",
    "\n",
    "# Test over 50 scenarios\n",
    "success = 0\n",
    "total_steps = 0\n",
    "\n",
    "for _ in range(50):\n",
    "    ok, steps = run()\n",
    "    if ok:\n",
    "        success += 1\n",
    "        total_steps += steps\n",
    "\n",
    "print(\"Success Rate:\", success / 50 * 100, \"%\")\n",
    "print(\"Average Path Length:\", total_steps / max(success, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c3539cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test Case 1 ---\n",
      "Rule fired: IF ['high_traffic', 'no_user_activity'] THEN DDoS\n",
      "Expected: DDoS, Detected: DDoS\n",
      "\n",
      "--- Test Case 2 ---\n",
      "Rule fired: IF ['many_ports_scanned', 'no_login_attempt'] THEN Port Scan\n",
      "Expected: Port Scan, Detected: Port Scan\n",
      "\n",
      "--- Test Case 3 ---\n",
      "Rule fired: IF ['unknown_process', 'high_cpu_usage'] THEN Malware\n",
      "Expected: Malware, Detected: Malware\n",
      "\n",
      "--- Test Case 4 ---\n",
      "Rule fired: IF ['suspicious_email', 'attachment_downloaded'] THEN Phishing\n",
      "Expected: Phishing, Detected: Phishing\n",
      "\n",
      "--- Test Case 5 ---\n",
      "Rule fired: IF ['unauthorized_access', 'data_exfiltration'] THEN Data Breach\n",
      "Expected: Data Breach, Detected: Data Breach\n",
      "\n",
      "--- Test Case 6 ---\n",
      "Expected: No threat, Detected: No threat\n",
      "\n",
      "--- Test Case 7 ---\n",
      "Expected: No threat, Detected: No threat\n",
      "\n",
      "--- Test Case 8 ---\n",
      "Expected: No threat, Detected: No threat\n",
      "\n",
      "--- Test Case 9 ---\n",
      "Expected: No threat, Detected: No threat\n",
      "\n",
      "--- Test Case 10 ---\n",
      "Expected: No threat, Detected: No threat\n",
      "\n",
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Mini Expert System for Cybersecurity Threat Diagnosis\n",
    "\n",
    "# Define rules as a list of dictionaries\n",
    "rules = [\n",
    "    {\"if\": [\"high_traffic\", \"no_user_activity\"], \"then\": \"DDoS\"},\n",
    "    {\"if\": [\"many_ports_scanned\", \"no_login_attempt\"], \"then\": \"Port Scan\"},\n",
    "    {\"if\": [\"unknown_process\", \"high_cpu_usage\"], \"then\": \"Malware\"},\n",
    "    {\"if\": [\"suspicious_email\", \"attachment_downloaded\"], \"then\": \"Phishing\"},\n",
    "    {\"if\": [\"unauthorized_access\", \"data_exfiltration\"], \"then\": \"Data Breach\"},\n",
    "]\n",
    "\n",
    "# Function to ask user for missing facts\n",
    "def ask_fact(fact):\n",
    "    response = input(f\"Is '{fact}' observed? (yes/no): \").strip().lower()\n",
    "    return response == \"yes\"\n",
    "\n",
    "# Forward chaining inference engine\n",
    "def diagnose():\n",
    "    known_facts = []\n",
    "    inferred_threats = []\n",
    "\n",
    "    print(\"=== Cybersecurity Threat Diagnosis ===\")\n",
    "\n",
    "    # Go through each rule\n",
    "    for rule in rules:\n",
    "        rule_satisfied = True\n",
    "        for fact in rule[\"if\"]:\n",
    "            if fact not in known_facts:\n",
    "                if ask_fact(fact):\n",
    "                    known_facts.append(fact)\n",
    "                else:\n",
    "                    rule_satisfied = False\n",
    "                    break  # This rule cannot fire\n",
    "        if rule_satisfied:\n",
    "            inferred_threats.append(rule[\"then\"])\n",
    "            print(f\"Rule fired: IF {rule['if']} THEN {rule['then']}\")\n",
    "\n",
    "    if inferred_threats:\n",
    "        print(\"\\nPossible Threats Detected:\")\n",
    "        for threat in inferred_threats:\n",
    "            print(f\"- {threat}\")\n",
    "    else:\n",
    "        print(\"\\nNo threats detected based on current facts.\")\n",
    "\n",
    "# Test system with 10 attack scenarios\n",
    "def test_system():\n",
    "    test_cases = [\n",
    "        [\"high_traffic\", \"no_user_activity\"],  # DDoS\n",
    "        [\"many_ports_scanned\", \"no_login_attempt\"],  # Port Scan\n",
    "        [\"unknown_process\", \"high_cpu_usage\"],  # Malware\n",
    "        [\"suspicious_email\", \"attachment_downloaded\"],  # Phishing\n",
    "        [\"unauthorized_access\", \"data_exfiltration\"],  # Data Breach\n",
    "        [\"high_traffic\"],  # Incomplete DDoS\n",
    "        [\"many_ports_scanned\"],  # Incomplete Port Scan\n",
    "        [\"unknown_process\"],  # Incomplete Malware\n",
    "        [\"suspicious_email\"],  # Incomplete Phishing\n",
    "        [\"unauthorized_access\"],  # Incomplete Data Breach\n",
    "    ]\n",
    "\n",
    "    correct = 0\n",
    "    for i, case in enumerate(test_cases):\n",
    "        print(f\"\\n--- Test Case {i+1} ---\")\n",
    "        known_facts = case.copy()\n",
    "        inferred_threats = []\n",
    "\n",
    "        for rule in rules:\n",
    "            if all(fact in known_facts for fact in rule[\"if\"]):\n",
    "                inferred_threats.append(rule[\"then\"])\n",
    "                print(f\"Rule fired: IF {rule['if']} THEN {rule['then']}\")\n",
    "\n",
    "        expected = rules[i][\"then\"] if i < 5 else \"No threat\"\n",
    "        detected = inferred_threats[0] if inferred_threats else \"No threat\"\n",
    "\n",
    "        print(f\"Expected: {expected}, Detected: {detected}\")\n",
    "        if expected == detected:\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = correct / len(test_cases) * 100\n",
    "    print(f\"\\nAccuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Run the interactive diagnosis\n",
    "# diagnose()\n",
    "\n",
    "# Run automated test\n",
    "test_system()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f12c60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "from copy import deepcopy\n",
    "\n",
    "# Tic-Tac-Toe board representation\n",
    "EMPTY = ' '\n",
    "PLAYER_X = 'X'\n",
    "PLAYER_O = 'O'\n",
    "\n",
    "def print_board(board):\n",
    "    print(\"\\n\".join([\" | \".join(row) for row in board]))\n",
    "    print()\n",
    "\n",
    "def check_winner(board):\n",
    "    lines = board + list(zip(*board))  # rows and columns\n",
    "    lines.append([board[i][i] for i in range(3)])  # main diagonal\n",
    "    lines.append([board[i][2 - i] for i in range(3)])  # anti-diagonal\n",
    "    for line in lines:\n",
    "        if line.count(line[0]) == 3 and line[0] != EMPTY:\n",
    "            return line[0]\n",
    "    if all(cell != EMPTY for row in board for cell in row):\n",
    "        return 'Draw'\n",
    "    return None\n",
    "\n",
    "def get_available_moves(board):\n",
    "    return [(r, c) for r in range(3) for c in range(3) if board[r][c] == EMPTY]\n",
    "\n",
    "def make_move(board, move, player):\n",
    "    new_board = deepcopy(board)\n",
    "    new_board[move[0]][move[1]] = player\n",
    "    return new_board\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ec74d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimax(board, depth, alpha, beta, maximizing, player):\n",
    "    opponent = PLAYER_O if player == PLAYER_X else PLAYER_X\n",
    "    winner = check_winner(board)\n",
    "    if winner == player:\n",
    "        return 1\n",
    "    elif winner == opponent:\n",
    "        return -1\n",
    "    elif winner == 'Draw':\n",
    "        return 0\n",
    "\n",
    "    if maximizing:\n",
    "        max_eval = -math.inf\n",
    "        for move in get_available_moves(board):\n",
    "            eval = minimax(make_move(board, move, player), depth + 1, alpha, beta, False, player)\n",
    "            max_eval = max(max_eval, eval)\n",
    "            alpha = max(alpha, eval)\n",
    "            if beta <= alpha:\n",
    "                break\n",
    "        return max_eval\n",
    "    else:\n",
    "        min_eval = math.inf\n",
    "        for move in get_available_moves(board):\n",
    "            eval = minimax(make_move(board, move, opponent), depth + 1, alpha, beta, True, player)\n",
    "            min_eval = min(min_eval, eval)\n",
    "            beta = min(beta, eval)\n",
    "            if beta <= alpha:\n",
    "                break\n",
    "        return min_eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c293a29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEMORY_LIMIT = 100\n",
    "\n",
    "class LimitedMemoryAgent:\n",
    "    def __init__(self, player, memory_limit=MEMORY_LIMIT):\n",
    "        self.player = player\n",
    "        self.memory_limit = memory_limit\n",
    "        self.state_counter = 0\n",
    "\n",
    "    def minimax_limited(self, board, depth, alpha, beta, maximizing):\n",
    "        if self.state_counter >= self.memory_limit:\n",
    "            # Stop exploring further when out of memory\n",
    "            return 0\n",
    "        self.state_counter += 1\n",
    "\n",
    "        winner = check_winner(board)\n",
    "        opponent = PLAYER_O if self.player == PLAYER_X else PLAYER_X\n",
    "\n",
    "        if winner == self.player:\n",
    "            return 1\n",
    "        elif winner == opponent:\n",
    "            return -1\n",
    "        elif winner == 'Draw':\n",
    "            return 0\n",
    "\n",
    "        if maximizing:\n",
    "            value = -math.inf\n",
    "            for move in get_available_moves(board):\n",
    "                eval = self.minimax_limited(make_move(board, move, self.player), depth + 1, alpha, beta, False)\n",
    "                value = max(value, eval)\n",
    "                alpha = max(alpha, value)\n",
    "                if beta <= alpha:\n",
    "                    break\n",
    "            return value\n",
    "        else:\n",
    "            value = math.inf\n",
    "            for move in get_available_moves(board):\n",
    "                eval = self.minimax_limited(make_move(board, move, opponent), depth + 1, alpha, beta, True)\n",
    "                value = min(value, eval)\n",
    "                beta = min(beta, value)\n",
    "                if beta <= alpha:\n",
    "                    break\n",
    "            return value\n",
    "\n",
    "    def best_move(self, board):\n",
    "        best_val = -math.inf\n",
    "        best_move = None\n",
    "        for move in get_available_moves(board):\n",
    "            self.state_counter = 0  # reset per move\n",
    "            move_val = self.minimax_limited(make_move(board, move, self.player), 0, -math.inf, math.inf, False)\n",
    "            if move_val > best_val:\n",
    "                best_val = move_val\n",
    "                best_move = move\n",
    "        return best_move\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "781f87e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing with memory limit = 20\n",
      "X | X | X\n",
      "  |   | O\n",
      "  |   | O\n",
      "\n",
      "Result: X\n",
      "X | O | X\n",
      "  | X | O\n",
      "O |   | X\n",
      "\n",
      "Result: X\n",
      "X | X | X\n",
      "O |   | O\n",
      "  |   |  \n",
      "\n",
      "Result: X\n",
      "X | X | O\n",
      "X | O |  \n",
      "X | O |  \n",
      "\n",
      "Result: X\n",
      "X | X | O\n",
      "O | X |  \n",
      "  | X | O\n",
      "\n",
      "Result: X\n",
      "X | X | X\n",
      "  |   |  \n",
      "O |   | O\n",
      "\n",
      "Result: X\n",
      "X | X | X\n",
      "  |   |  \n",
      "O | O |  \n",
      "\n",
      "Result: X\n",
      "X | X | X\n",
      "  |   | O\n",
      "  |   | O\n",
      "\n",
      "Result: X\n",
      "X | X | X\n",
      "  | O |  \n",
      "  |   | O\n",
      "\n",
      "Result: X\n",
      "X | X | O\n",
      "O | X | O\n",
      "  | X |  \n",
      "\n",
      "Result: X\n",
      "Win rate: 10/10 = 100%\n",
      "\n",
      "Testing with memory limit = 50\n",
      "X | X | X\n",
      "  |   |  \n",
      "O |   | O\n",
      "\n",
      "Result: X\n",
      "X | X | X\n",
      "O |   | O\n",
      "  |   |  \n",
      "\n",
      "Result: X\n",
      "X | X | O\n",
      "  | X | O\n",
      "O | X |  \n",
      "\n",
      "Result: X\n",
      "X | X | O\n",
      "O | X |  \n",
      "  | O | X\n",
      "\n",
      "Result: X\n",
      "X | X | X\n",
      "  |   | O\n",
      "  |   | O\n",
      "\n",
      "Result: X\n",
      "X | X | O\n",
      "X | X | O\n",
      "O | O | X\n",
      "\n",
      "Result: X\n",
      "X | O | X\n",
      "X | O | O\n",
      "O | X | X\n",
      "\n",
      "Result: Draw\n",
      "X | O | X\n",
      "  | X |  \n",
      "O | O | X\n",
      "\n",
      "Result: X\n",
      "X | X | O\n",
      "  | X |  \n",
      "O | O | X\n",
      "\n",
      "Result: X\n",
      "X | X | O\n",
      "X | X | O\n",
      "O |   | O\n",
      "\n",
      "Result: O\n",
      "Win rate: 8/10 = 80%\n",
      "\n",
      "Testing with memory limit = 100\n",
      "X | X | X\n",
      "  |   | O\n",
      "  | O |  \n",
      "\n",
      "Result: X\n",
      "X | X | X\n",
      "  |   |  \n",
      "O | O |  \n",
      "\n",
      "Result: X\n",
      "X | X | O\n",
      "X | O | O\n",
      "X |   |  \n",
      "\n",
      "Result: X\n",
      "X | X | X\n",
      "  |   |  \n",
      "O | O |  \n",
      "\n",
      "Result: X\n",
      "X | X | O\n",
      "X |   |  \n",
      "X | O | O\n",
      "\n",
      "Result: X\n",
      "X | X | X\n",
      "O |   |  \n",
      "  |   | O\n",
      "\n",
      "Result: X\n",
      "X | X | X\n",
      "  |   |  \n",
      "  | O | O\n",
      "\n",
      "Result: X\n",
      "X | O | X\n",
      "  | X | O\n",
      "O |   | X\n",
      "\n",
      "Result: X\n",
      "X | X | X\n",
      "  |   | O\n",
      "  |   | O\n",
      "\n",
      "Result: X\n",
      "X | X | O\n",
      "O | X | O\n",
      "  | X |  \n",
      "\n",
      "Result: X\n",
      "Win rate: 10/10 = 100%\n"
     ]
    }
   ],
   "source": [
    "def play_game(memory_limit_agent=True):\n",
    "    board = [[EMPTY]*3 for _ in range(3)]\n",
    "    player = PLAYER_X\n",
    "    limited_agent = LimitedMemoryAgent(PLAYER_X, memory_limit=MEMORY_LIMIT)\n",
    "    \n",
    "    while not check_winner(board):\n",
    "        if player == PLAYER_X:\n",
    "            if memory_limit_agent:\n",
    "                move = limited_agent.best_move(board)\n",
    "            else:\n",
    "                move = random.choice(get_available_moves(board))\n",
    "        else:\n",
    "            move = random.choice(get_available_moves(board))\n",
    "        \n",
    "        board = make_move(board, move, player)\n",
    "        player = PLAYER_O if player == PLAYER_X else PLAYER_X\n",
    "\n",
    "    print_board(board)\n",
    "    winner = check_winner(board)\n",
    "    print(\"Result:\", winner)\n",
    "    return winner\n",
    "\n",
    "# Example run\n",
    "for limit in [20, 50, 100]:\n",
    "    print(f\"\\nTesting with memory limit = {limit}\")\n",
    "    agent = LimitedMemoryAgent(PLAYER_X, memory_limit=limit)\n",
    "    wins = 0\n",
    "    for i in range(10):\n",
    "        result = play_game(memory_limit_agent=True)\n",
    "        if result == PLAYER_X:\n",
    "            wins += 1\n",
    "    print(f\"Win rate: {wins}/10 = {wins*10}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0208cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6c37fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\LAB 06\\Desktop\\New folder\n",
      "Files in this folder: ['OEL.ipynb', 'perfomance.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "print(\"Files in this folder:\", os.listdir())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31bf01ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\LAB 06\\Desktop\\New folder\\StudentsPerformance.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1c3e58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 8 columns):\n",
      " #   Column                       Non-Null Count  Dtype \n",
      "---  ------                       --------------  ----- \n",
      " 0   gender                       1000 non-null   object\n",
      " 1   race/ethnicity               1000 non-null   object\n",
      " 2   parental level of education  1000 non-null   object\n",
      " 3   lunch                        1000 non-null   object\n",
      " 4   test preparation course      1000 non-null   object\n",
      " 5   math score                   1000 non-null   int64 \n",
      " 6   reading score                1000 non-null   int64 \n",
      " 7   writing score                1000 non-null   int64 \n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 62.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gender                         0\n",
       "race/ethnicity                 0\n",
       "parental level of education    0\n",
       "lunch                          0\n",
       "test preparation course        0\n",
       "math score                     0\n",
       "reading score                  0\n",
       "writing score                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.describe()\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93eb071e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['gender', 'race/ethnicity', 'parental level of education', 'lunch',\n",
      "       'test preparation course', 'math score', 'reading score',\n",
      "       'writing score'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73d9c4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gender', 'race/ethnicity', 'parental level of education', 'lunch', 'test preparation course', 'math score', 'reading score', 'writing score']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e794d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gender', 'race/ethnicity', 'parental level of education', 'lunch', 'test preparation course', 'math score', 'reading score', 'writing score']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57cee5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gender  race/ethnicity  parental level of education  lunch  \\\n",
      "0       0               1                            1      1   \n",
      "1       0               2                            4      1   \n",
      "2       0               1                            3      1   \n",
      "3       1               0                            0      0   \n",
      "4       1               2                            4      1   \n",
      "\n",
      "   test preparation course  math score  reading score  writing score  \n",
      "0                        1          52             44             50  \n",
      "1                        0          49             62             64  \n",
      "2                        1          70             67             69  \n",
      "3                        1          27             29             20  \n",
      "4                        1          56             50             51  \n",
      "Columns: Index(['gender', 'race/ethnicity', 'parental level of education', 'lunch',\n",
      "       'test preparation course', 'math score', 'reading score',\n",
      "       'writing score'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 8 columns):\n",
      " #   Column                       Non-Null Count  Dtype\n",
      "---  ------                       --------------  -----\n",
      " 0   gender                       1000 non-null   int64\n",
      " 1   race/ethnicity               1000 non-null   int64\n",
      " 2   parental level of education  1000 non-null   int64\n",
      " 3   lunch                        1000 non-null   int64\n",
      " 4   test preparation course      1000 non-null   int64\n",
      " 5   math score                   1000 non-null   int64\n",
      " 6   reading score                1000 non-null   int64\n",
      " 7   writing score                1000 non-null   int64\n",
      "dtypes: int64(8)\n",
      "memory usage: 62.6 KB\n",
      "None\n",
      "gender                         0\n",
      "race/ethnicity                 0\n",
      "parental level of education    0\n",
      "lunch                          0\n",
      "test preparation course        0\n",
      "math score                     0\n",
      "reading score                  0\n",
      "writing score                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Show first 5 rows\n",
    "print(df.head())\n",
    "\n",
    "# Show columns\n",
    "print(\"Columns:\", df.columns)\n",
    "\n",
    "# Check basic info\n",
    "print(df.info())\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4934db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = \"math score\"\n",
    "X = df.drop(target_column, axis=1)\n",
    "y = df[target_column]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be5c9c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "df = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ec7bad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_enc = LabelEncoder()\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == \"object\":\n",
    "        X[col] = label_enc.fit_transform(X[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5d7e1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# For example, categorize 0-100 into 3 classes\n",
    "y = pd.cut(y, bins=[0, 50, 75, 100], labels=['Low', 'Medium', 'High'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d675d8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c45beda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 features: Index(['reading score', 'writing score', 'gender', 'race/ethnicity',\n",
      "       'parental level of education', 'lunch', 'test preparation course'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "top_features = importances.sort_values(ascending=False).head(10).index\n",
    "print(\"Top 10 features:\", top_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7776ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Low', 'Medium', 'High']\n",
      "Categories (3, object): ['Low' < 'Medium' < 'High']\n",
      "category\n"
     ]
    }
   ],
   "source": [
    "print(y_train.unique())\n",
    "print(y_train.dtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e457a24a",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), Index(['reading score', 'writing score', 'gender', 'race/ethnicity',\n       'parental level of education', 'lunch', 'test preparation course'],\n      dtype='object'))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LAB 06\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:173\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: '(slice(None, None, None), Index(['reading score', 'writing score', 'gender', 'race/ethnicity',\n       'parental level of education', 'lunch', 'test preparation course'],\n      dtype='object'))' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mInvalidIndexError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m results = {}\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m models.items():\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     model.fit(\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_features\u001b[49m\u001b[43m]\u001b[49m, y_train)\n\u001b[32m     18\u001b[39m     y_pred = model.predict(X_test[:, top_features])\n\u001b[32m     19\u001b[39m     acc = accuracy_score(y_test, y_pred)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LAB 06\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LAB 06\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3824\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3824\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_indexing_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3825\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LAB 06\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6072\u001b[39m, in \u001b[36mIndex._check_indexing_error\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   6068\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_check_indexing_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[32m   6069\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(key):\n\u001b[32m   6070\u001b[39m         \u001b[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[32m   6071\u001b[39m         \u001b[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m6072\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[31mInvalidIndexError\u001b[39m: (slice(None, None, None), Index(['reading score', 'writing score', 'gender', 'race/ethnicity',\n       'parental level of education', 'lunch', 'test preparation course'],\n      dtype='object'))"
     ]
    }
   ],
   "source": [
    "model.fit(X_train[top_features], y_train)\n",
    "y_pred = model.predict(X_test[top_features])\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
